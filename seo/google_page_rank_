#!/usr/bin/env python
# encoding utf8
# head1 NAME
#
# google_page_rank_
#
# DESCRIPTION
#
# Script for getting Google Page Rank of page
#
# original from http://pagerank.gamesaga.net/
# this version was adapted from http://code.google.com/p/corey-projects/source/browse/trunk/python2/pagerank.py
#   by Corey Goldberg - 2010
# which in turn was adapted from http://www.djangosnippets.org/snippets/221/
#  
#
# Licensed under the MIT license: http://www.opensource.org/licenses/mit-license.php
#
# APPLICABLE SYSTEMS
#
# Any
#
# CONFIGURATION
#
# link this plugin to the site you want (without the http://) and it will automatically
# generate the page rank for the site
#

import struct
import sys
import os
import urllib
import urllib2
import httplib
import re
import xml.etree.ElementTree

THIS_SCRIPT_NAME ="google_page_rank_"

class RankProvider(object):
	"""Abstract class for obtaining the page rank (popularity)
	from a provider such as Google or Alexa.

	"""
	def __init__(self, host, proxy=None, timeout=30):
		"""Keyword arguments:
		host -- toolbar host address
		proxy -- address of proxy server. Default: None
		timeout -- how long to wait for a response from the server.
		Default: 30 (seconds)

		"""
		self._opener = urllib2.build_opener()
		if proxy:
			self._opener.add_handler(urllib2.ProxyHandler({"http": proxy}))

		self._host = host
		self._timeout = timeout

	def get_rank(self, url):
		"""Get the page rank for the specified URL

		Keyword arguments:
		url -- get page rank for url

		"""
		raise NotImplementedError("You must override get_rank()")

class GooglePageRank(RankProvider):
	""" Get the google page rank figure using the toolbar API.
	Credits to the author of the WWW::Google::PageRank CPAN package
	as I ported that code to Python.

	"""
	def __init__(self, host="toolbarqueries.google.com", proxy=None, timeout=30):
		"""Keyword arguments:
		host -- toolbar host address: Default: toolbarqueries.google.com
		proxy -- address of proxy server (if required). Default: None
		timeout -- how long to wait for a response from the server.
		Default: 30 (seconds)

		"""
		super(GooglePageRank, self).__init__(host, proxy, timeout)
		self._opener.addheaders = [("User-agent", "Mozilla/4.0 (compatible; GoogleToolbar 2.0.111-big; Windows XP 5.1)")]

	def get_rank(self, url):
		# calculate the hash which is required as part of the get
		# request sent to the toolbarqueries url.
		ch = '6' + str(self._compute_ch_new("info:%s" % (url)))

		query = "http://%s/tbr?%s" % (self._host, urllib.urlencode((
			("client", "navclient-auto"),
			("ch", ch),
			("ie", "UTF-8"),
			("oe", "UTF-8"),
			("features", "Rank"),
			("q", "info:%s" % (url)))))

		response = self._opener.open(query, timeout=self._timeout)
		if response.getcode() == httplib.OK:
			data = response.read()
			if(not(data)):
				return(0)
			else:
				match = re.match("Rank_\d+:\d+:(\d+)", data)
				if match:
					rank = match.group(1)
					return int(rank)

	@classmethod
	def _compute_ch_new(cls, url):
		ch = cls._compute_ch(url)
		ch = ((ch % 0x0d) & 7) | ((ch / 7) << 2);

		return cls._compute_ch(struct.pack("<20L", *(cls._wsub(ch, i * 9) for i in range(20))))

	@classmethod
	def _compute_ch(cls, url):
		url = struct.unpack("%dB" % (len(url)), url)
		a = 0x9e3779b9
		b = 0x9e3779b9
		c = 0xe6359a60
		k = 0

		length = len(url)

		while length >= 12:
			a = cls._wadd(a, url[k+0] | (url[k+1] << 8) | (url[k+2] << 16) | (url[k+3] << 24));
			b = cls._wadd(b, url[k+4] | (url[k+5] << 8) | (url[k+6] << 16) | (url[k+7] << 24));
			c = cls._wadd(c, url[k+8] | (url[k+9] << 8) | (url[k+10] << 16) | (url[k+11] << 24));

			a, b, c = cls._mix(a, b, c)

			k += 12
			length -= 12

		c = cls._wadd(c, len(url));

		if length > 10: c = cls._wadd(c, url[k+10] << 24)
		if length > 9: c = cls._wadd(c, url[k+9] << 16)
		if length > 8: c = cls._wadd(c, url[k+8] << 8)
		if length > 7: b = cls._wadd(b, url[k+7] << 24)
		if length > 6: b = cls._wadd(b, url[k+6] << 16)
		if length > 5: b = cls._wadd(b, url[k+5] << 8)
		if length > 4: b = cls._wadd(b, url[k+4])
		if length > 3: a = cls._wadd(a, url[k+3] << 24)
		if length > 2: a = cls._wadd(a, url[k+2] << 16)
		if length > 1: a = cls._wadd(a, url[k+1] << 8)
		if length > 0: a = cls._wadd(a, url[k])

		a, b, c = cls._mix(a, b, c);

		# integer is always positive
		return c

	@classmethod
	def _mix(cls, a, b, c):
		a = cls._wsub(a, b); a = cls._wsub(a, c); a ^= c >> 13;
		b = cls._wsub(b, c); b = cls._wsub(b, a); b ^= (a << 8) % 4294967296;
		c = cls._wsub(c, a); c = cls._wsub(c, b); c ^= b >>13;
		a = cls._wsub(a, b); a = cls._wsub(a, c); a ^= c >> 12;
		b = cls._wsub(b, c); b = cls._wsub(b, a); b ^= (a << 16) % 4294967296;
		c = cls._wsub(c, a); c = cls._wsub(c, b); c ^= b >> 5;
		a = cls._wsub(a, b); a = cls._wsub(a, c); a ^= c >> 3;
		b = cls._wsub(b, c); b = cls._wsub(b, a); b ^= (a << 10) % 4294967296;
		c = cls._wsub(c, a); c = cls._wsub(c, b); c ^= b >> 15;

		return a, b, c

	@staticmethod
	def _wadd(a, b):
		return (a + b) % 4294967296

	@staticmethod
	def _wsub(a, b):
		return (a - b) % 4294967296


if __name__ == "__main__":
	full_caller_name = sys.argv[0]
	index_of_script = full_caller_name.find(THIS_SCRIPT_NAME)
	site_url = sys.argv[0][len(THIS_SCRIPT_NAME) + index_of_script:]


	urls = None
	if(site_url == ""):
		# try and get the URLs from the configuration file
		urls = os.environ.get("GOOGLE_PAGE_RANK_URLS")
		if(None == urls):
			print("Could not find the envirnoment variable GOOGLE_PAGE_RANK_URLS")
			sys.exit()
		else:
			urls = os.environ.get("GOOGLE_PAGE_RANK_URLS").split(",")
	else:
		urls = [site_url]

	# are we doing config/autoconfig?
	if(len(sys.argv) > 1):
		if (sys.argv[1]=="config"):
			print "graph_title Google PageRank"
			print "graph_vlabel PageRank"
			print "graph_category SEO"

			for url in urls:
				# in green
				print "PAGE_RANK_" + url.replace(".", "_") + ".label " + url + ""
				#print "PAGE_RANK_" + url.replace(".", "_") + ".colour 00cc00"
				print "PAGE_RANK_" + url.replace(".", "_") + ".draw AREA"

			print "graph_args --base 1000 "
			sys.exit()

	providers = (GooglePageRank(),)

	for p in providers:
		for url in urls:
			url = url.strip()
			if(url != ""):
				print("PAGE_RANK_" + site_url.replace(".", "_") + ".value %d" % (p.get_rank("http://" + url)))

